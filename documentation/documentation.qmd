---
title: BLN immigration project
subtitle: ""
format:
  scdefault-html:
    code-overflow: wrap
# remaining customizations in _metadata.yml
---

::: confidential
NOT FOR PUBLICATION
:::

This website documents BLN's work on the Deportation Data Project's collection of ICE datasets.


## Immigration data projects in the wild

### Deportation Data Project

The [Deportation data project](https://deportationdata.org/index.html)
is run by Graeme Blair of UCLA and David Hausman of Berkeley Law.
Together, they've sued DHS to obtain individual-level data from ICE and
CBP about encounters, arrests, detainers, detentions and removals. So
far it doesn't seem that they've gotten much from CBP, but they have
obtained the data from ICE. It gets updated irregularly, most recently
in September 2025 for data ending in July.

We spoke with Hausman in September, who told us a bit about the project
and about some of the uses for his data. In particular, he said that
news organizations had done a good job using local arrest data, for what
it's worth, but that the others take some decision-making and are a
little harder. In his view, the detention data would have the most use
for local reporters and is the most under-used.

Graeme is undertaking a project to make LIONS more accessible to
researchers and reporters -- I've had one interaction with him but
didn't hear back after I responded to his message.

The project is currently setting up "slicers" for their data, but is not
really trying to make it more accessible than that. Hausman said he
would welcome any help we can give in helping reporters use it -- they
are getting a lot of questions and requests for help, and they can't
handle it all. They need this help more than any technical help.

We talked with them about how Big Local could help fill that void.

They have [excellent documentation](https://deportationdata.org/docs/ice/codebook.html) of the terms used in deportation datasets - it's a great guide to what we know and what we don't about the data.

### Follow up from symposium of reporters

In June, Berkeley Journalism and a few other places [hosted a
symposium](https://docs.google.com/document/d/1TOFnulRtde2uO2xGK-ln0MYpgEZZzGDqsGoJSX6GeMU/edit?usp=sharing)
of reporters, experts, etc. to discuss immigration reporting. Our
contact there is Andrés Cediel, a documentarian with a lot of interest
in immigration issues. We spoke with him on Oct 10. They want to make
the data more transparent, and are focused on visualizations that could
be embedded. Others who are still involved include Mark Lima of CBS and
(I think) Lourdes Duarte from Chicago WGN.

Their inspiration was the COVID tracking project from the Atlantic.

His story ideas were pretty straightforward: US citizens getting caught
up in raids, looking at children , those without criminal records. They
are working with the Berkeley-based California News Fellowship (the
group that is funded by the Calif. government to fill holes in local
reporting.)

Ryan explained our model of working with a national outlet to do a story
that we can help get localized by partners that we've worked with
before, then have training materials, cleaned data, etc. to provide to
anyone once we know what we're doing. In a followup note, Andrès still
seemed focused on dashboard / visualizations, but Ryan clarified that.

He mentioned that LAT did a good job using the data after their
protests.

### Guardian US

Will Craft, who has done a lot of work with Big Local in the past, is
using the Deportation Data project pretty effectively, and may be interested
in being our national partner.

After talking with him in late October, it seems that he is quite understandably very focused on getting to stories that haven't been done yet, warning us that this is a pretty crowded space for national stories. But he'll help us when it comes time to work with local reporters. For example, his story on [ICE violating its own policies on detention](https://www.theguardian.com/us-news/2025/oct/30/ice-hidden-detention-sites) could be localized. He has method to get to this, though it seems like it's reasonably straightforward. The big thing is that the detention data reported in aggregate by ICE is midnight -- you need to work with actual times to get this right.





### Enforcement dashboard

The [immigration enforcement dashboard](https://austinkocher.substack.com/p/live-new-immigration-enforcement) was initialy released in September, but includes only arrest data for the time being. The project is led by [Austin Kocher](https://austinkocher.com/) an asst. research professor at Syracuse Journalism in the Office of Research and
Creative Technology.[^1]

[^1]: These are usually grant management divisions of schools, and there
    is nothing about it in the Newhouse School's website. So it's really
    unclear whether he works there or not. He's associated with Margaret
    Talev's group as well. Although he says he has a lot of research and
    media outlet work, it seems really out of date -- CSpan last year,
    and then nothing after 2022. He worked at TRAC while getting his PhD
    in geography.

There is a proof of concept at
<https://enforcementdashboard.com/ice-arrests/> for arrests, but it's
unclear if they are going beyond that. It's done by Kocher's company,
Relevant Research, which also has a site called
<https://detentionreports.com>. His numbers in detention can't be
separately sourced because he is using an imputation method to convert
year-to-date averages into daily populations by month.[^2]

[^2]: He starts with the [facilities
    report](https://www.ice.gov/detain/detention-management) published
    by ICE bi-monthly, then [calculates an
    "Interval"](https://relevant-research.com/assets/pdf/methodology_writeup.pdf)
    value. He takes a whole paper to say that he estimates the most
    recent two weeks' values by backing out the number of days. (ADP is
    calculated as total pop / total \# days for the fiscal year. Taking
    two time periods, can back out an ADP for the two weeks by taking
    ADP*Days period 1 - ADP* Days period 2 to get Days for Period 2, and
    then divide by the number of days.)

He has gotten historical numbers by week by going to the wayback
machine. ICE takes down the old links, but WAYBACK has them

On <https://austinkocher.substack.com/> , he has done some work
explaining what is in the data and what isn't.

The enforcement dashboard has some issues with functionality -- my guess
is that although the concept worked for aggregated stats that are in the
ICE detention data, it doesn't work for datasets with way more values in
it.

### Other possible sources

#### Interest groups

* Cato Institute, immigration project. It's unclear who we'd want to speak with - they have several people writing articles, including Scott Lincicome and David J. Bier. Bier published [at least one article](https://www.cato.org/blog/ice-arresting-1100-percent-more-noncriminals-streets-2017) referencing "nonpublic data" acquired by Cato that isn't anywhere else.

#### Reporters

* LA Times reporters who have been working with all of the data

* Tim Henderson, Stateline - Tim's Stateline package is the one that has been localized by a lot of the smaller newsrooms affiliated with it.

* I spoke with Anthony DeBarros, WSJ, who [analyzed the Deportation Data Project's datasets](https://www.wsj.com/us-news/ice-deportations-charts-b3593e29?st=Gbjv6u&reflink=desktopwebshare_permalink) in context of other available sources. He is happy to help us, and had some good ideas for stories, such as focusing on communities that local reporters know are important in their areas.



### Tracking cases through the system

TBD

## Progress notes

::: {.todo}
- [ ] Get a list of famous cases that should be followed through the system
  - Moving around detention
  - Arrest at courthouse
  - US citizens
  - Deaths
  - Children
:::

::: {.question}
-   [x] Is the unique identifier the same over time? ANSWER : NO
-   [ ] What is the impact of this coming from ICE's Integrated Enforcement Database? Is any CBP data included? (NO) Should it be?

:::


## Folder structure

I have not put the `/data/` files into the github repo, but everything needed to get there is in the programs. (I don't want to make copies of the Deportation Data Project's work, so I am referring anyone who wants the originals to their site. )

In my project, the folder structure is:

<!-- why isn't my wrapping working? I don't care that much, but it annoys me -->
::: {.sourceCode .code .pre style="text-wrap:wrap;font-family:monospace;"}

```
+-- documentation (most name are self-explanatory
|   `-- master_data_dictionary_lookups.xlsx
|   `-- documenatation.html is currently the root of the website, though other pages are public
+-- programs (names are self-explanatory)
+-- data
|   +-- raw
|   |  +-- ddp : Data exactly as provided by deportation data project with the original names.
|   +-- clean: datasets we'll eventually want to split up / share
|   +-- interim: Datasets we won't share but are conveniences when we're getting to clean
+-- share
|   +-- data: shared datasets in any form
|   +-- code: any SQL , R, Python code we want to share with people

```
:::

